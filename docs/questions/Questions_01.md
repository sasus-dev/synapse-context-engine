# Architectural Questions (Dec 26, 2025)

## ðŸ§  Core Architecture Questions

### 1.Â **Hyperedge Activation Semantics**

When spreading activation hits a hyperedgeÂ `e = {A, B, C, D}`:

- **Does activation flow to ALL members simultaneously?**Â (like broadcasting)
- **Or does it flow proportionally?**Â (split energy across members)
- **Or does it depend on the "role" of each node in the hyperedge?**

Example: HyperedgeÂ `Meeting_2024_12_15 = {Alice, Bob, Topic_X, Decision_Y}`

If activation enters viaÂ `Alice`, should:

- **Option A:**Â All members get equal energy boost
- **Option B:**Â `Bob`Â gets more (co-participant),Â `Topic_X`Â gets medium,Â `Decision_Y`Â gets less
- **Option C:**Â Activation requires minimum threshold from MULTIPLE members before hyperedge "fires"

**Why this matters:**Â This changes the graph dynamics entirely. Option C creates AND-gate logic (concept activation requires multiple evidence sources), which could be powerful for reducing false positives.

---

### 2.Â **Temporal Decay Strategy**

There are two time dimensions:

1. **Propagation time**Â (t in spreading activation)
2. **Real-world time**Â (when memories were created/accessed)

**Question:**Â How do these interact?

**Scenario:**Â User asks: "What was the client's feedback on the dashboard?"

- Memory A: Direct feedback (2 months old, not accessed since)
- Memory B: Recent meeting mentioning "dashboard issues" (1 week old)
- Memory C: Dashboard config file (3 months old, accessed yesterday)

Currently, the heat diffusion would favor B > C > A. But A is the mostÂ **semantically relevant**. How is the balance achieved between:

- **Temporal recency**Â (when created/accessed)
- **Relational proximity**Â (graph distance from query)
- **Semantic relevance**Â (embedding similarity)

**Possible solution:**Â Multi-factor scoring:

finalScore = 

  Î± * activationEnergy + 

  Î² * recencyScore + 

  Î³ * semanticSimilarity + 

  Î´ * userAccessPattern

But how are Î±, Î², Î³, Î´ set?Â **Could these be learned per-user?**

---

### 3.Â **Contradiction Detection Mechanism**

Detecting contradictions is mentioned as a feature, but how is it implemented?

**Concrete scenario:**

- Node A:Â `UserPreference(theme: "dark")`Â (created 2024-06-01)
- Node B:Â `UserPreference(theme: "light")`Â (created 2024-12-01)

**Detection approaches:**

**Option 1: Schema-based**

- Predefined rules: "UserPreference nodes with same property but different values = contradiction"
- Pro: Explicit, auditable
- Con: Requires manual schema design

**Option 2: Embedding-based**

- IfÂ `sim(A, B) > 0.9`Â butÂ `A.value != B.value`, flag as potential contradiction
- Pro: Automatic discovery
- Con: False positives

**Option 3: Graph topology**

- Look for "conflict edges" manually labeled by user or LLM
- Pro: Flexible
- Con: Requires active curation

**Question:**Â Which approach is being implemented? AndÂ **how does SCE resolve contradictions once detected?**

- Always use most recent?
- Present both to LLM with timestamps?
- Ask user to resolve explicitly?

---

### 4.Â **Active Focus Multiplicity**

Real users multitask. Currently, there is ONE Active Focus node. But what if:

- User has Project_A open in one tab
- Slack conversation about Project_B in another
- Email referencing Project_C

**Should SCE:**

**Option A:**Â Maintain multiple simultaneous foci with different strengths

activeFoci = [

  {node: Project_A, strength: 1.0},   // primary (current tab)

  {node: Project_B, strength: 0.6},   // secondary (mentioned recently)

  {node: Project_C, strength: 0.3}    // tertiary (referenced in email)

]

**Option B:**Â Fast-switch single focus based on UI events (current behavior)

**Option C:**Â Maintain "working memory set" (last N accessed nodes remain partially active)

**Question:**Â Has user behavior been tested to see if single-focus is sufficient, or are there cases where multi-focus would help?

---

### 5.Â **Weight Learning - The Forgetting Problem**

The current Hebbian rule (Eq. 3) onlyÂ **increases**Â weights. Over time, everything becomes connected.

**Real-world scenario:**

- User worked with Tool_X on Project_Y for 3 months
- Strong weight forms:Â `Project_Y â†” Tool_X`Â (w = 0.95)
- User switches to Tool_Z, never uses Tool_X again
- 6 months later, asks about Project_Y
- SCE still strongly activates Tool_X (stale association)

**How is this handled?**

**Possible approaches:**

**1. Time-based decay:**

w_ij(t) = w_ij(t-1) * exp(-Î» * Î”t_unused)

Weights decay if edge isn't traversed. But thenÂ `last_traversed`Â needs to be tracked per edge.

**2. Competitive learning:**Â When new edgeÂ `Project_Y â†” Tool_Z`Â strengthens, weaken competing edges:

if (strengthen(Y â†” Z)) {

  weaken(Y â†” X)  // where X competes with Z (same type)

}

**3. Explicit forgetting events:**Â User says "I don't use Tool_X anymore" â†’ system prunes related edges

**4. LLM-guided pruning:**Â Periodically ask LLM: "Are these associations still valid?" and prune based on response

**Which strategy is being used or planned?**

---

## ðŸ”§ Implementation Deep Dives

### 6.Â **SQL CTE Performance Cliff**

Recursive CTEs are used for graph traversal.

**At what graph size does this break?**

Has profiling been done for:

- 1K nodes, 5K edges
- 10K nodes, 50K edges
- 100K nodes, 500K edges

**Specific question:**Â What is the measured latency distribution?

- p50 (median)
- p95 (outliers)
- p99 (worst case)

If CTEs become a bottleneck, consider:

**Alternative 1: Application-level graph traversal**

class ActivationEngine {

  traverse(seedNodes: Node[], maxDepth: number): Node[] {

    const queue = seedNodes.map(n => ({node: n, energy: 1.0, depth: 0}));

    const visited = new Map<string, number>();

    while (queue.length > 0) {

      const {node, energy, depth} = queue.shift()!;

      if (depth >= maxDepth || energy < threshold) continue;

      for (const edge of node.outgoingEdges) {

        const newEnergy = energy * edge.weight * decay;

        if (newEnergy > threshold) {

          queue.push({node: edge.target, energy: newEnergy, depth: depth+1});

        }

      }

    }

    return Array.from(visited.entries());

  }

}

**Alternative 2: Graph database (Neo4j, Memgraph)**Â Native graph traversal with Cypher. But then "local-first" is compromised.

**Alternative 3: Precomputed neighborhoods**Â MaintainÂ `k-hop neighborhood`Â materialized views. Trade freshness for speed.

**Question:**Â Has the performance wall been hit yet, or is this premature optimization?

---

### 7.Â **Concurrency & Consistency**

The weight updates (Eq. 3) require read-modify-write:

UPDATE synapses 

SET weight = weight + Î· * (1 - weight)

WHERE source_id = ? AND target_id = ?

**What happens if:**

- User interacts from Desktop app
- Simultaneously interacts from Mobile app
- Both trigger weight updates on same edge

**Current behavior:**Â Last write wins (likely)

**Potential issues:**

- Lost updates (one device's learning erased)
- Weight drift (both devices have slightly different graphs over time)

**Possible solutions:**

**1. Operational Transform (OT) / CRDT:**Â Each edge weight is a CRDT counter. Updates commute.

**2. Centralized write queue:**Â All updates funnel through single service. Adds latency, loses local-first benefits.

**3. Periodic sync with conflict resolution:**Â Devices sync periodically, use max(weight) or timestamp-based resolution.

**4. Embrace eventual consistency:**Â Accept that weight values may differ slightly across devices. Is this acceptable?

**Question:**Â Is multi-device sync in scope for Mini Me OS? If yes, how is it handled?

---

### 8.Â **Hypergraph â†’ Binary Edge Impedance Mismatch**

The paper describes hypergraphs, but the SQL schema shows binary edges:

source_id â†’ target_id

**How are hyperedges actually stored?**

**Option A: Edge explosion (standard approach)**Â HyperedgeÂ `{A, B, C, D}`Â becomes:

A â†’ B

A â†’ C  

A â†’ D

B â†’ C

B â†’ D

C â†’ D

(6 edges for 4 nodes)

**Option B: Hyperedge entity**

CREATE TABLE hyperedges (id, label);

CREATE TABLE hyperedge_members (hyperedge_id, node_id, role);

Then spreading activation must handle both:

- Binary edges (direct propagation)
- Hyperedge membership (broadcast to all members)

**Question:**Â Which approach is being used? And how is the decision made to create a hyperedge vs. binary edges?

**Related:**Â Is thereÂ **automatic hyperedge detection**? E.g., if LLM extracts entities from meeting notes, does it create:

- Individual nodes:Â `Alice`,Â `Bob`,Â `Decision_X`
- One hyperedge linking them all
- Or just binaryÂ `Alice â†’ Decision_X`,Â `Bob â†’ Decision_X`?

---

### 9.Â **Cold Start Problem - Hybrid Strategy**

This is mentioned as an open question. Concrete scenario:

**Day 1:**Â New user, empty graphÂ **User asks:**Â "Schedule a meeting with the design team"

**Pure SCE:**Â Has no nodes yet. No associations. No spreading activation.Â **Fails.**

**Fallback to RAG:**Â Retrieves relevant documents from user's files/emails. Works, but no memory.

**Hybrid approach:**

**Phase 1 (Days 1-7):**Â Use RAG, butÂ **log all retrieved chunks as nodes**

- Every RAG retrieval creates a node
- Co-retrieved chunks get edges between them
- User interactions strengthen weights

**Phase 2 (Days 7-30):**Â Gradually weight SCE higher

contextScore = (1 - Î±) * RAG_score + Î± * SCE_score

// where Î± = min(1.0, days_since_start / 30)

**Phase 3 (Day 30+):**Â Pure SCE with RAG fallback only if SCE returns empty

**Question:**Â Is something like this being implemented? What is the cutover strategy?

**Bonus question:**Â Can the system detect when a userÂ **already has structure**Â (imports existing notes/projects) and skip cold start?

---

### 10.Â **Information Gain Calculation - The Token Budget Problem**

The MMR-style pruning (Eq. 7) ranks nodes by relevance/redundancy. ButÂ **when to stop?**

**Scenario:**Â Query activates 50 nodes. After MMR ranking:

1. Node A (score 0.95)
2. Node B (score 0.89)
3. Node C (score 0.76) ...
4. Node Z (score 0.12)

**How many are injected into LLM context?**

**Option A: Fixed budget**Â (e.g., "top 10 nodes")

- Simple, predictable
- Wastes tokens if top 10 are redundant

**Option B: Dynamic threshold**Â (e.g., "all nodes > 0.5")

- Adapts to query
- Could inject 3 nodes or 30 nodes

**Option C: Marginal gain cutoff**Â (e.g., "stop when next node adds <10% information")

let totalInfo = 0;

for (const node of rankedNodes) {

  const marginalGain = node.score - redundancy(node, selected);

  if (marginalGain < threshold * totalInfo) break;

  selected.push(node);

  totalInfo += marginalGain;

}

**Option D: Token budget**Â Keep adding nodes until LLM's context limit is hit (e.g., 8K tokens)

**Question:**Â Which strategy is being used? Has over-injection (too much context) vs under-injection (too little) been observed?

---

## ðŸŽ¯ Product/UX Questions

### 11.Â **Explainability & Trust**

When SCE retrieves context, can the user seeÂ **why**?

**Example UI:**

Query: "Update the client deck"

ðŸ“Š Context Retrieved:

  âœ“ Project_ClientA (activation: 0.95)

    â””â”€ Related via: Active Focus

  âœ“ Template_Corporate (activation: 0.78)

    â””â”€ Related via: Project_ClientA â†’ uses â†’ Template

  âœ“ Contact_Sarah (activation 0.65)

    â””â”€ Related via: ClientA â†’ primary contact â†’ Sarah

  âœ— Skipped_Node_X (activation: 0.42, redundancy: 0.89)

**Question:**Â Is the activation path exposed to users? Or is it purely internal?

**Related:**Â Can usersÂ **correct mistakes**?

- "Actually, don't associate Project_X with Tool_Y"
- Explicit negative feedback to break spurious connections

---

### 12.Â **Adversarial Inputs & Graph Poisoning**

**Scenario:**Â User accidentally opens spam email with subject "URGENT: Click here to claim prize"

SCE extracts entities:

- `Event: URGENT_ACTION`
- `Topic: Prize_Claim`

These get connected to whatever the Active Focus was (e.g.,Â `Project_Work`).

**Now:**Â Whenever user works onÂ `Project_Work`, spam-related nodes get activated.

**How is graph pollution prevented?**

**Option A: Confidence thresholds**Â Only create nodes if entity extraction confidence > 0.8

**Option B: User confirmation**Â "I noticed you accessed [SpamEmail]. Should I remember this?"

**Option C: Automatic decay**Â If a node is never accessed again after creation, its weights decay rapidly

**Option D: Outlier detection**Â If a node has very different embedding from its neighbors, flag as anomaly

**Question:**Â Has this been encountered in testing? What is the mitigation strategy?

---

### 13.Â **Memory Consolidation - Sleep for AI?**

Biological memory consolidates during sleep (replay of experiences, strengthening important connections, pruning weak ones).

**Could SCE have a "consolidation phase"?**

**During idle time (e.g., overnight):**

1. **Replay:**Â Simulate activation patterns from recent sessions
2. **Reinforce:**Â Strengthen frequently co-activated paths
3. **Prune:**Â Remove edges with weight < threshold
4. **Abstract:**Â Create meta-nodes (e.g., "Projects related to Machine Learning")

**Example:**Â User worked on 5 different ML projects this month. Consolidation creates:

- Meta-node:Â `Cluster_ML_Projects`
- Links to all 5 projects
- Inherits common properties

Now, future queries about "ML work" activate the cluster, pulling in relevant context.

**Question:**Â Is this in scope, or too speculative? Could be a v2 feature.

---

### 14.Â **Multi-User Graphs - Team Knowledge**

Mini Me OS is personal (Digital Twin), but teams share context.

**Scenario:**Â Team of 3 working on same project

- Alice's graph: Strong associations with Design_Tool_X
- Bob's graph: Strong associations with Code_Framework_Y
- Carol's graph: Strong associations with Client_Feedback_Z

**Should their graphs merge? Federate? Stay separate?**

**Option A: Separate graphs with shared nodes**Â Each user has their own graph, but certain nodes (Projects, shared documents) are shared. Weights remain personal.

**Option B: Collaborative graph**Â One graph per team. Everyone's interactions contribute to shared weights. Risk: One power user dominates.

**Option C: Graph federation**Â When Alice asks about "the project," SCE queries:

- Alice's personal graph (high weight)
- Team graph (medium weight)
- Bob/Carol's graphs if relevant (low weight)

**Question:**Â Is multi-user in scope? If not now, is the architecture extensible to support it later?

---

### 15.Â **Failure Mode Analysis**

When does SCEÂ **fail gracefully**Â vsÂ **fail catastrophically**?

**Test cases:**

**A. User asks completely off-domain question:**

- "What's the weather in Tokyo?"
- Expected: SCE returns empty, fallback to RAG or web search

**B. User asks ambiguous question:**

- "What did we decide?"
- Multiple decisions in recent history. How does SCE disambiguate?

**C. User asks question requiring reasoning over time:**

- "How has our approach to X evolved over the past year?"
- Requires retrieving nodes from different time periods, comparing them

**D. User's graph becomes too dense:**

- Everything connects to everything (weight inflation)
- Activation floods the entire graph. How is this prevented?

**Question:**Â Have these scenarios been stress-tested? What breaks?

---

## ðŸš€ Strategic Questions

### 16.Â **SCE as a Service vs. Embedded Library**

The current architecture seems monolithic (SCE + UI in one app). But could SCE be:

**Option A: Standalone service**

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚   Mini Me   â”‚

â”‚   OS (UI)   â”‚

â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜

       â”‚ HTTP/gRPC

â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”

â”‚     SCE     â”‚

â”‚   Engine    â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Other apps could use SCE as a memory layer.

**Option B: Embedded library**

import { SynapseEngine } from '@sasus/sce';

const engine = new SynapseEngine(config);

Developers integrate SCE into their own apps.

**Option C: Protocol/spec**Â Define SCE as a spec (like ActivityPub). Multiple implementations possible.

**Question:**Â What is the vision for SCE adoption? Personal tool, platform, or protocol?

---

### 17.Â **Benchmark Design - What Would Prove SCE Works?**

Quantitative validation is needed.Â **What metrics would convince skeptics?**

**Proposed benchmark tasks:**

**Task 1: Cross-domain retrieval**

- Dataset: User's work history (projects, emails, meetings)
- Query: "Who should I talk to about the API redesign?"
- Gold standard: Human-annotated relevant people
- Metric: Precision@5, Recall@10

**Task 2: Temporal reasoning**

- Query: "What changed in our strategy since Q2?"
- Requires comparing nodes from different time periods
- Metric: Accuracy of extracted changes vs. ground truth

**Task 3: Token efficiency**

- Same query, compare token usage: RAG vs. SCE
- Metric: Task completion rate per 1K tokens

**Task 4: Consistency over time**

- Track same query asked weekly for 3 months
- Metric: Coherence of responses as memory evolves

**Question:**Â Which of these resonate? What other tasks would demonstrate SCE's value?

---

### 18.Â **Open Source Strategy**

The code has been open-sourced. What is the goal?

**Option A: Build community of contributors**

- Need: Good docs, clear architecture, welcoming issues
- Risk: Project scope creep, maintenance burden

**Option B: Validate idea via external testing**

- Need: Easy setup, demo datasets, benchmarks
- Risk: Low adoption if too complex

**Option C: Establish as academic reference implementation**

- Need: Reproducible experiments, detailed paper
- Risk: Forks without attribution

**Question:**Â What does success look like for the open-source project in 6 months?

---

## ðŸ”® Future-Looking Questions

### 19.Â **Multi-Modal Memory**

Right now, nodes are text-based. But what about:

- **Images:**Â User's design mockups, photos from meetings
- **Audio:**Â Recorded conversations, voice memos
- **Code:**Â Actual code files, not just references

**How would these fit in the hypergraph?**

**Possible approach:**

- Store multimodal embeddings (CLIP for images, Whisper for audio)
- Create edges based on co-occurrence in same context
- Spreading activation uses embedding similarity for cross-modal propagation

**Example:**Â User asks "What did Sarah say about the dashboard?"

- Activates:Â `Person_Sarah`,Â `Topic_Dashboard`
- Propagates to:Â `Audio_Meeting_2024_12_15.wav`
- Retrieves: Transcript segment where Sarah mentions dashboard

**Question:**Â Is multimodal support on the roadmap?

---

### 20.Â **AI Safety Implications**

It is mentioned that SCE could help with AI alignment.Â **How, specifically?**

**Possible angles:**

**A. Inspectability:**

- SCE's reasoning is in the graph topology (visible)
- vs. black-box vector embeddings
- Allows auditing: "Why did the AI suggest X?"

**B. Alignment via structure:**

- Explicitly model user values as high-weight nodes
- Ensure they're always activated alongside relevant queries
- Prevents drift from user preferences

**C. Contradiction detection:**

- If AI generates response contradicting known user beliefs, SCE flags it
- Safety layer: "This contradicts your stated preference for X"

**D. Provenance tracking:**

- Every decision traces back to source memories
- Enables accountability: "This recommendation came from Document Y"

**Question:**Â Which of these are actively being worked on? Is this primarily theoretical or are there concrete implementations?

---

## Final Meta-Question

### 21.Â **What's the One Thing You're Most Uncertain About?**

A complex system has been built. Of all the design decisions, which one causes the most uncertainty?

- Is it scalability (will it work at 100K nodes)?
- Is it correctness (are the weights learning the right things)?
- Is it usefulness (will users actually benefit from this vs. RAG)?
- Is it architecture (were the right abstractions picked)?

**Reason for asking:**Â The answer will reveal where the most help/validation/testing is needed.

---

## ðŸŽ Bonus: Specific Code Review Questions

If desired, share a few key code snippets (the spreading activation implementation, weight update logic, or hypergraph schema), and a detailed code review can be done with:

- Algorithmic complexity analysis
- Edge case identification
- Refactoring suggestions
- Bug potential

---

### 22.Â **Long-Term Goal Adherence (Goal Nodes)**

**The Challenge:**Â In long sessions, the system may "drift" (Contextual Drift) asÂ `workingMemory`Â updates with new inputs. How do we ensure the AI remembers theÂ _original_Â high-level objective (e.g., "Build a React App") even after 50 messages of debugging specific CSS quirks that push the original project context out of the top-3 buffer?

**The Options:**

- **Option A (Sticky Context):**Â Pin the first context node permanently inÂ `workingMemory`.
- **Option B (Goal Nodes):**Â Introduce a dedicatedÂ `goal`Â node type that functions as a "Gravity Well" (Persistent Energy Source).
- **Option C (Periodic Reminders):**Â Re-inject the system prompt every N turns.

**Recommendation:**Â **Option B (Goal Nodes)**. AÂ `goal`Â node differs from aÂ `context`Â node because:

1. It isÂ **never**Â evicted from Working Memory automatically (or has a separate "Goal Buffer").
2. It emits a constant "Beacon Signal" (Energy) every cycle, ensuring goal-relevant concepts remain activated (Warm) despite topic shifts.